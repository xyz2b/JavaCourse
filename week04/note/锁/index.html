<!DOCTYPE html>
<html>
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta charset="utf-8" />
		<link rel="stylesheet" type="text/css" href="css/style.css" />
		<title>锁</title>
	</head>
<body>
<h1>锁</h1>

<h2>锁分类</h2>

<p>在并发程序中，串行操作是会降低可伸缩性，并且上下文切换也会减低性能。在锁上发生竞争时将会导致这两种问题，使用独占锁时保护受限资源的时候，基本上是采用串行方式—-每次只能有一个线程能访问它。所以对于可伸缩性来说最大的威胁就是独占锁。</p>

<p>我们一般有三种方式降低锁的竞争程度： </p>

<p>1.减少锁的持有时间 </p>

<p>2.降低锁的请求频率 </p>

<p>3.减小锁的粒度(方法上加锁 —&gt; 代码块加锁，减少锁的范围；对同一个对象加锁 —&gt; 对多个不同的对象加锁，减少同一个对象上锁的争抢)</p>

<h3>对竞争的态度</h3>

<p>乐观锁(java.util.concurrent包中的原子类)与悲观锁(Synchronized)</p>

<ul>
	<li>乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。</li>
	<li>悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。</li>
</ul>

<p>实现方式</p>

<p>悲观锁的实现方式是加锁，加锁既可以是对代码块加锁（如Java的synchronized关键字），也可以是对数据加锁（如MySQL中的排它锁）。</p>

<p>乐观锁的实现方式主要有两种：CAS机制和版本号机制。</p>

<h3>对等待锁的人是否公平而言</h3>

<p>公平锁new ReentrantLock(true)与非公平锁new ReentrantLock()</p>

<p>JVM&nbsp;按随机、就近原则分配锁的机制则称为不公平锁。加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待</p>

<p>公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁。加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得</p>

<p>公平锁就是在获取锁之前会先判断等待队列是否为空或者自己是否位于队列头部，该条件通过才能继续获取锁。</p>

<p>其实对于非公平锁，只要线程进入了等待队列，队列里面依然是FIFO的原则，跟公平锁的顺序是一样的。</p>

<p>线程切换的开销，其实就是非公平锁效率高于公平锁的原因，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销。</p>

<p>ReentrantLock、ReadWriteLock默认都是非公平模式</p>

<p>Java&nbsp;中的&nbsp;synchronized&nbsp;是非公平锁</p>

<p>总结: 不公平锁可以插队，公平锁不能插队必须老实的排队</p>

<p>图解</p>

<figure><img src="DraggedImage.tiff"/></figure>

<h3>是否可以共享</h3>

<p>共享锁与独享锁: ReadWriteLock，其读锁是共享锁，其写锁是独享锁</p>

<p>独享锁(排他锁)一次只能被一个线程所持有。如果线程T对数据A加上排他锁后，则其他线程不能再对A加任何类型的锁。获得排他锁的线程既能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁</p>

<p>共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排他锁。获得共享锁的线程只能读数据，不能修改数据。</p>

<p>独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。</p>

<p>ReentrantReadWriterLock里面读锁是共享锁，写锁是独享锁</p>

<h3>可重入锁和不可重入锁</h3>

<p>可重入锁指的是可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class），这样的锁就叫做可重入锁。</p>

<p>ReentrantLock和sychronized都是可重入锁</p>

<p>不可重入锁，与可重入锁相反，不可递归调用，递归调用就发生死锁。</p>

<h2>锁优化</h2>

<h3>重量级锁</h3>

<p>Synchronized是通过对象内部的一个叫做监视器锁(monitor)来实现的。但是监视器锁本质又是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换就需要从用户态转换到核心态，这个成本非常高，状态之间的额转换需要相对比较长的时间，所以Synchronized效率比较低。因此，这种依赖于操作系统Mutex Lock所实现的锁称之为”重量级锁”</p>

<h3>轻量级锁(LightWeight Locking)</h3>

<p>解决的问题:</p>

<p>轻量级锁是JDK6时引入的，其中”轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的，因此传统的锁机制就被称为”重量级锁”。轻量级锁并不是用来代替重量级锁的，它设计的初衷是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能损耗</p>

<p>锁的状态总共有四种: 无锁状态、偏向锁、轻量级锁、重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级到重量级锁(但是锁的升级是单向的，只能从低到高升级，不会出现锁的降级)。JDK1.6以后默认是开启偏向锁和轻量级锁的，也可以通过参数<code>-XX: -UseBiasedLocking</code>来禁用偏向锁。锁的状态保存在对象头中，以32位的JDK为例:</p>

<p>HotPot虚拟机对象头MarkWord</p>

<figure><img src="DraggedImage.png"/></figure>

<p>加锁过程:</p>

<p>1.在代码进入同步块时，如果同步对象锁状态为无锁状态(锁标志位为01，偏向模式位为0)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的MarkWord的拷贝，官方称之为Displaced Mark Word。这时线程堆栈和对象头的状态如下图所示</p>

<figure><img src="DraggedImage-1.png"/></figure>

<p>2.拷贝对象头中的Mark Word复制到锁记录中</p>

<p>3.拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向Object Mark Word。如果更新成功，则执行步骤4，否则执行步骤5</p>

<p>4.如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为”00”，即表示此对象处于轻量级锁定状态，这时候线程对象与对象头的状态如下图所示</p>

<figure><img src="DraggedImage-2.png"/></figure>

<p>5.如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁(已有线程持有了该对象的轻量级锁)，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为”10”，Mark Word中存储的就是指向重量级锁(互斥量)的指针(之前持有轻量级锁的线程，改为现在持有重量级锁)，后面等待锁的线程也要进入阻塞状态。而当前线程(当前尝试获取轻量级锁的线程，改为尝试获取重量级锁)便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程</p>

<p>解锁过程:</p>

<p>1.通过CAS操作尝试使用线程中复制的Displaced Mark Word替换当前对象的Mark Word</p>

<p>2.如果替换成功，整个同步过程就完成了</p>

<p>3.如果替换失败，说明有其他线程尝试过获取该对象锁(此时锁已膨胀，当前对象的Mark Word已经改为指向重量级锁的指针了(之前持有轻量级锁的该线程继续持有该对象锁，只不过变成了重量级锁)，而不是之前指向当前线程栈帧的指针了，所以会CAS替换失败，其余尝试获取该对象锁的线程都被挂起了(不考虑自旋))，那就要在释放锁的同时，唤醒被挂起的线程</p>

<h3>偏向锁(Biased Locking)</h3>

<p>解决的问题:</p>

<p>引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令(由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能消耗必须小于节省下来的CAS原子指令的性能消耗)。上面说过，轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能</p>

<p>加锁过程(TODO: 没有理太清楚，需要再看看):</p>

<p>初始锁定:</p>

<p>当所锁对象第一次被线程获取时，先判断是否能够进入偏向模式，虚拟将会把对象头中的偏向模式位设置为1，锁标志位设置为01，表示进入偏向模式。同时使用CAS操作把获取到这个锁的线程ID记录在对象头的Mark Word中。如果CAS操作成功，持有偏向锁的线程以后每次进入这个锁相关的同步块时，虚拟机都可以不再进行任何同步操作(例如加锁、解锁以及对Mark Word的更新操作等)</p>

<p>1.确认Mark Word中偏向模式位是否为1，锁标志位是否为01 —— 确认进入偏向模式，为可偏向状态，偏向锁可用</p>

<p>2.如果为可偏向状态，则测试线程ID是否指向当前线程，如果是进入步骤4，否则进入步骤3</p>

<p>3.如果线程ID并未指向当前线程，则通过CAS操作竞争锁，如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行步骤5，如果竞争失败，执行步骤4</p>

<p>4.如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点(SafePoint)时获取偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码</p>

<p>5.执行同步代码</p>

<p>解锁过程:</p>

<p>偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点(在这个时间点上没有字节码正在执行)，它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销后恢复到未锁定(标志位为01)或轻量级锁(标记位为00)的状态</p>

<h3>重量级锁、轻量级锁、偏向锁之间的转换</h3>

<figure><img src="DraggedImage-3.png"/></figure>

<h3>其他优化</h3>

<h4>自旋锁与自适应自旋(Adaptive Spinning)</h4>

<p>问题:</p>

<p>互斥同步对性能最大的影响是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态完成。</p>

<p>共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得</p>

<p>解决方案:</p>

<p>如果物理机器有一个以上的处理器或者处理器核心，能让两个以上的线程同时并行执行，可以让后面请求锁的那个线程”稍微等一会”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，只须让线程执行一个忙循环(自旋)，这就是所谓的自旋锁</p>

<p>JDK6后默认开启。</p>

<p>上述解决方案引发的其他问题:</p>

<p>自旋等待不能代替阻塞，且先不说对处理器数量的要求，自旋等待本身虽然避免了线程切换的开销，但它是要占用处理器时间的，所以如果锁被占用的时间很短，自旋等待的效果就会非常好，反之如果锁被占用的时间很长，那么自旋的线程只会白白浪费处理器资源，而不会做任何有价值的工作，这就会带来性能浪费。</p>

<p>解决方案:</p>

<p>因此自旋等待时间必须有一定的限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程。自旋次数默认是10次，可以通过参数<code>-XX: PreBlockSpin</code>来修改</p>

<p>方案改进:</p>

<p>引入自适应自旋，自适应意味着自旋的时间不再是固定的，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，进而允许自选等待持续相对更长的时间；如果对于某个锁，自旋很少成功获得过锁，那么在以后要获取这个锁时将有可能直接省略掉自旋过程，以避免浪费处理器资源</p>

<h4>锁消除(Lock Elimination)</h4>

<p>解决的问题:</p>

<p>锁消除是指虚拟机即时编译器在运行时，对一些代码要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除</p>

<p>如何解决:</p>

<p>锁消除的主要判定依据来源于逃逸分析的数据支持，如果判断一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问，那就可以把它们当做栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行</p>

<p>举例:</p>

<p>下面这段简单的代码仅仅是输出三个字符串的相加结果，无论是源代码字面上，还是程序语义上都没有进行同步</p>

<pre><code>public String concatString(String s1, String s2, String s3){
	return s1 + s2 + s3;
}</code></pre>

<p>由于String是一个不可变类，对字符串的连接操作总是通过生成新的String对象来进行的，因此javac编译器会对String连接做自动优化。在JDK5以后的版本中，会转换为StringBuilder对象的连接append()操作</p>

<pre><code>public String concatString(String s1, String s2, String s3){
	StringBuilder sb = new StringBuilder();
	sb.append(s1);
	sb.append(s2);
	sb.append(s3);
	return sb.toString();
}</code></pre>

<p>每个StringBuilder.append()方法中都有一个同步块，锁就是sb对象。虚拟机观察变量sb，经过逃逸分析后发现它的动态作用域被限制在concatString()方法内部，也就是sb的所有引用都永远不会逃逸到concatString()方法之外，其他线程无法访问到它，所以这里虽然有锁，但是可以被安全地消除掉。在解释执行时这里仍然会加锁，但在经过服务端编译器的即时编译之后，这段代码就会忽略所有的同步措施而直接执行</p>

<h4>锁粗化</h4>

<p>原则上，在编写代码时，总是推荐将同步块的作用范围限制的尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变少，即使存在锁竞争，等待锁的线程也尽可能块地拿到</p>

<p>问题:</p>

<p>大多数情况下，上面原则是正确的，但是如果一系列的连续操作都对同一个镀锡反复加锁和解锁，甚至加锁操作是出现在循环体之内，那即使没有线程竞争，频繁地进行互斥同步操作也会导致不必要的性能损耗。如上面字符串连接的代码中连续的append()方法就属于这类情况</p>

<p>解决:</p>

<p>如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁，将会把加锁同步的范围扩展(粗化)到整个操作序列的外部，以上面字符串连接代码为例，就是扩展到第一个append()操作之前直到最后一个append()操作之后，这样只需要加锁一次即可</p>

<h4>分段锁</h4>

<p>在某些情况下我们可以将锁分解技术进一步扩展为一组独立对象上的锁进行分解，这成为分段锁。其实说的简单一点就是：容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。</p>

<p>比如：在ConcurrentHashMap中使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。假设使用合理的散列算法使关键字能够均匀的分部，那么这大约能使对锁的请求减少到越来的1/16。也正是这项技术使得ConcurrentHashMap支持多达16个并发的写入线程。</p>

<p>当然，任何技术必有其劣势，与独占锁相比，维护多个锁来实现独占访问将更加困难而且开销更加大。</p>

</body>
</html>

